<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
body {font-family: Arial;}

/* Style the tab */
.tab {
    overflow: hidden;
    border: 1px solid #ccc;
    background-color: #f1f1f1;
}

/* Style the buttons inside the tab */
.tab button {
    background-color: inherit;
    float: left;
    border: none;
    outline: none;
    cursor: pointer;
    padding: 14px 16px;
    transition: 0.3s;
    font-size: 17px;
}

/* Change background color of buttons on hover */
.tab button:hover {
    background-color: #ddd;
}

/* Create an active/current tablink class */
.tab button.active {
    background-color: #ccc;
}

/* Style the tab content */
.tabcontent {
    display: none;
    padding: 6px 12px;
    border: 1px solid #ccc;
    border-top: none;
}
</style>
</head>
<body>

<div class="tab">
  <button class="tablinks" onclick="openCity(event, 'Main')" id="defaultOpen">Main</button>
  <button class="tablinks" onclick="openCity(event, 'Learn')">Learn</button>
</div>

<div id="Main" class="tabcontent">
	<table width="700px" cellpadding="2" cellspacing="0" class="TG" style="word-break:break-all;">

	<!--//產生方法:
		1. 進入 https://www.tablesgenerator.com/html_tables 
		2. 複製ods檔案整理的結果(最後一行包含a herf資訊)
		3. 貼上
		4. 選擇Theme
		5. 下面要勾選Enable table sorting
		6. 產生出來的html程式碼要做以下處理:
		  取代"&lt;" -> "<" (小於符號)
		  取代"&gt;" -> ">" (大於符號)
		  取代"<br>" -> "" (空字串)
		7. 貼到這裡
		8. 放到...\word_representation\eric890006.github.io
		註:按照以上步驟，ods上面的姓名特殊字元不用處理
	//-->

	<style type="text/css">
	.tg {border-collapse:collapse;border-spacing:0;border-color:#aabcfe;}
	.tg td{font-family:Arial, sans-serif;font-size:14px;padding:3px 1px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#aabcfe;color:#669;background-color:#e8edff;border-top-width:1px;border-bottom-width:1px;}
	.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:3px 1px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#aabcfe;color:#039;background-color:#b9c9fe;border-top-width:1px;border-bottom-width:1px;}
	.tg .tg-vn4c{background-color:#D2E4FC}
	.tg .tg-yw4l{vertical-align:top}
	.tg .tg-6k2t{background-color:#D2E4FC;vertical-align:top}
	th.tg-sort-header::-moz-selection { background:transparent; }th.tg-sort-header::selection   { background:transparent; }th.tg-sort-header { cursor:pointer; }table th.tg-sort-header:after { content:''; float:right; margin-top:7px; border-width:0 4px 4px; border-style:solid; border-color:#404040 transparent; visibility:hidden; }table th.tg-sort-header:hover:after { visibility:visible; }table th.tg-sort-desc:after,table th.tg-sort-asc:after,table th.tg-sort-asc:hover:after { visibility:visible; opacity:0.4; }table th.tg-sort-desc:after { border-bottom:none; border-width:4px 4px 0; }

	body {font-family: sans-serif;background-color: #f7f6eb;color: #333;}
	#mainContainer {width: 900px;margin: auto;}
	h2 {text-align: center;}
	p, blockquote {margin-left: 50px; text-align: justify}
	ul {display: block; margin-left: 50px}
	h4 {text-align: left;}
	</style>
	<h4>Click the Labels to sort.</h4>
	<table id="tg-Jb0Jr" class="tg">
	 <tr>
	  <th class="tg-031e">預設</th>
	  <th class="tg-031e">詞義</th>
	  <th class="tg-031e">句子</th>
	  <th class="tg-yw4l">修正</th>
	  <th class="tg-yw4l">中文</th>
	  <th class="tg-yw4l">NE</th>
	  <th class="tg-yw4l">其他</th>
	  <th class="tg-yw4l">AUTHORS</th>
	  <th class="tg-yw4l">TITLE</th>
	  <th class="tg-yw4l">CONFERENCE</th>
	  <th class="tg-yw4l">YEAR</th>
	  <th class="tg-yw4l">LINKS</th>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">01</td>
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Yang-Yin Lee, Ting-Yu Yen, Hen-Hsen Huang, Yow-Ting Shiue, and Hsin-Hsi Chen</td>
	  <td class="tg-6k2t">GenSense: A Generalized Sense Retrofitting Model</td>
	  <td class="tg-6k2t">COLING</td>
	  <td class="tg-6k2t">2018</td>
	  <td class="tg-6k2t"><a href="http://nlg.csie.ntu.edu.tw/nlpresource/GenSense/">GenSense(with trained)</a> <a href="https://github.com/y95847frank/GenSense">GenSense</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">02</td>
	  <td class="tg-yw4l">o</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">o</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Ting-Yu Yen, Yang-Yin Lee, Hen-Hsen Huang and Hsin-Hsi Chen</td>
	  <td class="tg-yw4l"><a href="https://dl.acm.org/citation.cfm?id=3186906">That Makes Sense: Joint Sense Retrofitting from Contextual and Ontological Information</a></td>
	  <td class="tg-yw4l">TheWebConf</td>
	  <td class="tg-yw4l">2018</td>
	  <td class="tg-yw4l"><a href="https://github.com/y95847frank/Joint-Retrofitting">Joint-Retrofitting</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">03</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Fei Sun, Jiafeng Guo, Yanyan Lan, Jun Xu, and Xueqi Cheng</td>
	  <td class="tg-6k2t">Inside Out: Two Jointly Predictive Models for Word Representations and Phrase Representations</td>
	  <td class="tg-6k2t">AAAI</td>
	  <td class="tg-6k2t">2016</td>
	  <td class="tg-6k2t"><a href="http://ofey.me/projects/InsideOut/">SEING/BEING</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">04</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Minh-Thang Luong, Richard Socher, and Christopher D. Manning</td>
	  <td class="tg-yw4l">Better Word Representations with Recursive Neural Networks for Morphology</td>
	  <td class="tg-yw4l">CoNLL</td>
	  <td class="tg-yw4l">2013</td>
	  <td class="tg-yw4l"><a href="http://stanford.edu/~lmthang/morphoNLM/">cwCsmRNN/hsmnCsmRNN</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">05</td>
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Ignacio Iacobacci, Mohammad Taher Pilehvar, and Roberto Navigli</td>
	  <td class="tg-6k2t"><a href="http://www.aclweb.org/anthology/P15-1010">SensEmbed: Learning Sense Embeddings for Word and Relational Similarity</a></td>
	  <td class="tg-6k2t">ACL-IJCNLP</td>
	  <td class="tg-6k2t">2015</td>
	  <td class="tg-6k2t"><a href="http://lcl.uniroma1.it/sensembed/">SensEmbed</a> <a href="http://lcl.uniroma1.it/babelfied-wikipedia/">BabelNet synsets</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">06</td>
	  <td class="tg-yw4l">o</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Ignacio Iacobacci, Mohammad Taher Pilehvar, and Roberto Navigli</td>
	  <td class="tg-yw4l">Embeddings for word sense disambiguation: An evaluation study</td>
	  <td class="tg-yw4l">ACL</td>
	  <td class="tg-yw4l">2016</td>
	  <td class="tg-yw4l"><a href="https://github.com/iiacobac/ims_wsd_emb">ims_wsd_emb</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">07</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Rémi Lebret and Ronan Collobert</td>
	  <td class="tg-6k2t">Word Embeddings through Hellinger PCA</td>
	  <td class="tg-6k2t">EACL</td>
	  <td class="tg-6k2t">2014</td>
	  <td class="tg-6k2t"><a href="http://lebret.ch/words/">Hellinger PCA</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">08</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Luisa Bentivogli, Pamela Forner, Bernardo Magnini, and Emanuele Pianta </td>
	  <td class="tg-yw4l">Revising the wordnet domains hierarchy: semantics, coverage and balancing</td>
	  <td class="tg-yw4l">ACL workshop</td>
	  <td class="tg-yw4l">2004</td>
	  <td class="tg-yw4l"><a href="http://wndomains.fbk.eu/publications.html">WordNet Domains</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">09</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">John Wieting, Mohit Bansal, Kevin Gimpel, Karen Livescu, and Dan Roth</td>
	  <td class="tg-6k2t">From Paraphrase Database to Compositional Model and Back</td>
	  <td class="tg-6k2t">TACL</td>
	  <td class="tg-6k2t">2015</td>
	  <td class="tg-6k2t"><a href="http://ttic.uchicago.edu/~wieting/">Paragram Embeddings</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">10</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Jun Suzuki and Masaaki Nagata</td>
	  <td class="tg-yw4l">Right-truncatable Neural Word Embeddings</td>
	  <td class="tg-yw4l">NAACL</td>
	  <td class="tg-yw4l">2016</td>
	  <td class="tg-yw4l"><a href="http://www.kecl.ntt.co.jp/icl/lirg/members/jun/agreement.html">Right-truncatable</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">11</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">John Wieting, Mohit Bansal, Kevin Gimpel, and Karen Livescu</td>
	  <td class="tg-6k2t">Charagram: Embedding words and sentences via character n-grams</td>
	  <td class="tg-6k2t">EMNLP</td>
	  <td class="tg-6k2t">2016</td>
	  <td class="tg-6k2t"><a href="http://ttic.uchicago.edu/~wieting/">CHARAGRAM</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">12</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">o</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Hua He, Kevin Gimpel, and Jimmy Lin</td>
	  <td class="tg-yw4l">Multi-perspective sentence similarity modeling with convolutional neural networks</td>
	  <td class="tg-yw4l">EMNLP</td>
	  <td class="tg-yw4l">2015</td>
	  <td class="tg-yw4l"><a href="http://hohocode.github.io/textSimilarityConvNet/">MP-CNN-Torch</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">13</td>
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Guang-He Lee, and Yun-Nung Chen</td>
	  <td class="tg-6k2t"><a href="https://arxiv.org/pdf/1704.04601.pdf">MUSE: Modularizing Unsupervised Sense Embeddings</a></td>
	  <td class="tg-6k2t">EMNLP</td>
	  <td class="tg-6k2t">2017</td>
	  <td class="tg-6k2t"><a href="https://github.com/MiuLab/MUSE">MUSE</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">14</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Eric H. Huang, Richard Socher, Christopher D. Manning, and Andrew Y. Ng</td>
	  <td class="tg-yw4l">Improving word representations via global context and multiple word prototypes</td>
	  <td class="tg-yw4l">ACL</td>
	  <td class="tg-yw4l">2012</td>
	  <td class="tg-yw4l"><a href="http://ai.stanford.edu/~ehhuang/">GC</a> <a href="http://www.socher.org/index.php/Main/ImprovingWordRepresentationsViaGlobalContextAndMultipleWordPrototypes">GC(new)</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">15</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Massimiliano Mancini, Jose Camacho-Collados, Ignacio Iacobacci, and Roberto Navigli</td>
	  <td class="tg-6k2t">Embedding Words and Senses Together via Joint Knowledge-Enhanced Training</td>
	  <td class="tg-6k2t">CoNLL</td>
	  <td class="tg-6k2t">2017</td>
	  <td class="tg-6k2t"><a href="http://lcl.uniroma1.it/sw2v">SW2V</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">16</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">o</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Manaal Faruqui, Jesse Dodge, Sujay Jauhar, Chris Dyer, Eduard Hovy, and Noah Smith</td>
	  <td class="tg-yw4l"><a href="https://www.cs.cmu.edu/~hovy/papers/15HLT-retrofitting-word-vectors.pdf">Retrofitting word vectors to semantic lexicons</a></td>
	  <td class="tg-yw4l">NAACL</td>
	  <td class="tg-yw4l">2015</td>
	  <td class="tg-yw4l"><a href="https://github.com/mfaruqui/retrofitting">retrofitting</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">17</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Nikola Mrkšić, Diarmuid Ó Séaghdha, Blaise Thomson, Milica Gašić, Lina Rojas-Barahona, Pei-Hao Su , David Vandyke, Tsung-Hsien Wen, and Steve Young</td>
	  <td class="tg-6k2t"><a href="http://www.aclweb.org/anthology/N16-1018">Counter-fitting word vectors to linguistic constraints</a></td>
	  <td class="tg-6k2t">HLT-NAACL</td>
	  <td class="tg-6k2t">2016</td>
	  <td class="tg-6k2t"><a href="https://github.com/nmrksic/counter-fitting">counter-fitting</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">18</td>
	  <td class="tg-yw4l">o</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">o</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Sujay Kumar Jauhar, Chris Dyer, and Eduard Hovy</td>
	  <td class="tg-yw4l"><a href="https://pdfs.semanticscholar.org/8b96/8bfa6a9d3e3713c9c9ff2971e333efe1343b.pdf">Ontologically Grounded Multi-sense Representation Learning for Semantic Vector Space Models</a></td>
	  <td class="tg-yw4l">HLT-NAACL</td>
	  <td class="tg-yw4l">2015</td>
	  <td class="tg-yw4l"><a href="https://github.com/sjauhar/SenseRetrofit">SenseRetrofit</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">19</td>
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Ettinger, Allyson, Philip Resnik, and Marine Carpuat</td>
	  <td class="tg-6k2t">Retrofitting Sense-Specific Word Vectors Using Parallel Text</td>
	  <td class="tg-6k2t">HLT-NAACL</td>
	  <td class="tg-6k2t">2016</td>
	  <td class="tg-6k2t"><a href="http://ling.umd.edu/~aetting/retropd.html">sense-specific parallel text</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">20</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">o</td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Jiahuan Pei, Cong Zhang, Degen Huang, and Jianjun Ma</td>
	  <td class="tg-yw4l">Combining word embedding and semantic lexicon for Chinese word similarity computation</td>
	  <td class="tg-yw4l">ICCPOL</td>
	  <td class="tg-yw4l">2016</td>
	  <td class="tg-yw4l"><a href="https://github.com/JiahuanPei/NLPCC-2016-CLSC">NLPCC-2016-CLSC</a> <a href="http://tcci.ccf.org.cn/conference/2016/pages/page05_evadata.html">NLPCC 2016 Shared Task Sample Data</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">22</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Yunfang Wu, and Wei Li</td>
	  <td class="tg-6k2t">Overview of the NLPCC-ICCPOL 2016 Shared Task: Chinese Word Similarity Measurement</td>
	  <td class="tg-6k2t">ICCPOL</td>
	  <td class="tg-6k2t">2016</td>
	  <td class="tg-6k2t"></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">24</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l">o</td>
	  <td class="tg-yw4l">Stanisław Jastrzebski, Damian Leśniak, and Wojciech Marian Czarnecki</td>
	  <td class="tg-yw4l">How to evaluate word embeddings? On importance of data efficiency and simple supervised tasks</td>
	  <td class="tg-yw4l">arxiv</td>
	  <td class="tg-yw4l">2017</td>
	  <td class="tg-yw4l"><a href="https://github.com/kudkudak/word-embeddings-benchmarks">word-embeddings-benchmarks</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">25</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t">Yulia Tsvetkov, Manaal Faruqui, Wang Ling, Guillaume Lample, and Chris Dyer</td>
	  <td class="tg-6k2t">Evaluation of word vector representations by subspace alignment</td>
	  <td class="tg-6k2t">EMNLP</td>
	  <td class="tg-6k2t">2015</td>
	  <td class="tg-6k2t"><a href="https://github.com/ytsvetko/qvec">qvec</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">26</td>
	  <td class="tg-yw4l">o</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Ben Athiwaratkun and Andrew Gordon Wilson</td>
	  <td class="tg-yw4l"><a href="https://arxiv.org/pdf/1704.08424.pdf">Multimodal Word Distributions</a></td>
	  <td class="tg-yw4l">ACL</td>
	  <td class="tg-yw4l">2017</td>
	  <td class="tg-yw4l"><a href="https://github.com/benathi/word2gm">Word2GM </a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">27</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Shaohua Li, Jun Zhu and Chunyan Miao</td>
	  <td class="tg-6k2t">A Generative Word Embedding Model and its Low Rank Positive Semidefinite Solution</td>
	  <td class="tg-6k2t">EMNLP</td>
	  <td class="tg-6k2t">2015</td>
	  <td class="tg-6k2t"><a href="https://github.com/askerlee/topicvec">TopicVec</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">28</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Shaohua Li1, Tat-Seng Chua, Jun Zhu and Chunyan Miao</td>
	  <td class="tg-yw4l">Generative Topic Embedding: a Continuous Representation of Documents</td>
	  <td class="tg-yw4l">ACL</td>
	  <td class="tg-yw4l">2016</td>
	  <td class="tg-yw4l"><a href="https://github.com/askerlee/topicvec">TopicVec</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">29</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">o</td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Perozzi, Bryan and Al-Rfou, Rami and Skiena, Steven</td>
	  <td class="tg-6k2t"><a href="http://www.perozzi.net/publications/14_kdd_deepwalk.pdf">DeepWalk: Online Learning of Social Representations</a></td>
	  <td class="tg-6k2t">KDD</td>
	  <td class="tg-6k2t">2014</td>
	  <td class="tg-6k2t"><a href="https://github.com/phanein/deepwalk">DeepWalk</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">30</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">o</td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Tang, Jian and Qu, Meng and Wang, Mingzhe and Zhang, Ming and Yan, Jun and Mei, Qiaozhu</td>
	  <td class="tg-yw4l"><a href="https://arxiv.org/pdf/1503.03578.pdf">LINE: Large-scale Information Network Embedding</a></td>
	  <td class="tg-yw4l">WWW</td>
	  <td class="tg-yw4l">2015</td>
	  <td class="tg-yw4l"><a href="https://github.com/tangjianpku/LINE">LINE</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">31</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">o</td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Grover, Aditya and Leskovec, Jure</td>
	  <td class="tg-6k2t"><a href="https://arxiv.org/pdf/1607.00653.pdf">node2vec: Scalable Feature Learning for Networks</a></td>
	  <td class="tg-6k2t">KDD</td>
	  <td class="tg-6k2t">2016</td>
	  <td class="tg-6k2t"><a href="https://github.com/aditya-grover/node2vec">node2vec</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">32</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">o</td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Wang, Daixin and Cui, Peng and Zhu, Wenwu</td>
	  <td class="tg-yw4l"><a href="http://www.kdd.org/kdd2016/papers/files/rfp0191-wangAemb.pdf">Structural Deep Network Embedding</a></td>
	  <td class="tg-yw4l">KDD</td>
	  <td class="tg-yw4l">2016</td>
	  <td class="tg-yw4l"><a href="https://github.com/suanrong/SDNE">SDNE</a></td>
	 </tr>
	  <tr>
	  <td class="tg-6k2t">33</td>
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Mancini, Massimiliano and Camacho-Collados, Jose and Iacobacci, Ignacio and Navigli, Roberto</td>
	  <td class="tg-6k2t"><a href="https://arxiv.org/pdf/1612.02703.pdf">Embedding Words and Senses Together via Joint Knowledge-Enhanced Training</a></td>
	  <td class="tg-6k2t">CoNLL</td>
	  <td class="tg-6k2t">2017</td>
	  <td class="tg-6k2t"><a href="http://lcl.uniroma1.it/sw2v">sw2v</a></td>
	 </tr>
	  <tr>
	  <td class="tg-yw4l">34</td>
	  <td class="tg-yw4l">o</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">o</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Bollegala, Danushka and Alsuhaibani, Mohammed and Maehara, Takanori and Kawarabayashi, Ken-ichi</td>
	  <td class="tg-yw4l"><a href="https://arxiv.org/pdf/1511.06438.pdf">Joint Word Representation Learning Using a Corpus and a Semantic Lexicon</a></td>
	  <td class="tg-yw4l">AAAI</td>
	  <td class="tg-yw4l">2016</td>
	  <td class="tg-yw4l"><a href="https://github.com/Bollegala/jointreps">jointreps</a></td>
	 </tr>
	  <tr>
	  <td class="tg-6k2t">35</td>
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Rothe, Sascha and Schütze, Hinrich</td>
	  <td class="tg-6k2t"><a href="https://arxiv.org/pdf/1507.01127">Autoextend: Extending word embeddings to embeddings for synsets and lexemes</a></td>
	  <td class="tg-6k2t">ACL-IJCNLP</td>
	  <td class="tg-6k2t">2015</td>
	  <td class="tg-6k2t"><a href="http://www.cis.lmu.de/~sascha/AutoExtend/">AutoExtend </a></td>
	 </tr>
	  <tr>
	  <td class="tg-yw4l">36</td>
	  <td class="tg-yw4l">o</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">o</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Li, Qi and Li, Tianshi and Chang, Baobao</td>
	  <td class="tg-yw4l"><a href="https://pdfs.semanticscholar.org/f708/ac0b62923ebef88723f996702f742d50e05a.pdf">Multi-phase Word Sense Embedding Retrofitting with Lexical Ontology</a></td>
	  <td class="tg-yw4l">???</td>
	  <td class="tg-yw4l">2016</td>
	  <td class="tg-yw4l"><a href="https://milesqli.github.io/">Author's page </a></td>
	 </tr>
	  <tr>
	  <td class="tg-6k2t">37</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t">o</td>
	  <td class="tg-6k2t">Wang, Peifeng and Li, Shuangyin and Pan, Rong</td>
	  <td class="tg-6k2t"><a href="http://www.shuangyin.li/publications/KBGAN.pdf">Incorporating GAN for Negative Sampling in Knowledge Representation Learning</a></td>
	  <td class="tg-6k2t">AAAI</td>
	  <td class="tg-6k2t">2018</td>
	  <td class="tg-6k2t"></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">38</td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td>
	  <td class="tg-yw4l">Jeffrey Pennington, Richard Socher, and Christopher D. Manning</td>
	  <td class="tg-yw4l"><a href="https://www.aclweb.org/anthology/D14-1162">GloVe: Global Vectors for Word Representation</a></td>
	  <td class="tg-yw4l">EMNLP</td>
	  <td class="tg-yw4l">2014</td>
	  <td class="tg-yw4l"><a href="http://nlp.stanford.edu/projects/glove/">glove</a> <a href="https://github.com/GradySimon/tensorflow-glove">glove(tensorflow)</a> <a href="https://github.com/hans/glove.py">glove(python)</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">39</td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td>
	  <td class="tg-6k2t">Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean</td>
	  <td class="tg-6k2t"><a href="https://arxiv.org/pdf/1301.3781.pdf">Efficient Estimation of Word Representations in Vector Space</a></td>
	  <td class="tg-6k2t">ICLR</td>
	  <td class="tg-6k2t">2013</td>
	  <td class="tg-6k2t"><a href="https://code.google.com/archive/p/word2vec/">word2vec</a> <a href="https://github.com/deborausujono/word2vecpy">word2vec (python)</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">40</td>
	  <td class="tg-yw4l"></td><!-- sense -->
	  <td class="tg-yw4l"></td><!-- sentence -->
	  <td class="tg-yw4l"></td><!-- retrofitting -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l">o</td><!-- others -->
	  <td class="tg-yw4l">Ono, Masataka, Makoto Miwa, and Yutaka Sasaki</td>
	  <td class="tg-yw4l"><a href="https://www.aclweb.org/anthology/N15-1100">Word embedding-based antonym detection using thesauri and distributional information</a></td>
	  <td class="tg-yw4l">NAACL</td>
	  <td class="tg-yw4l">2015</td>
	  <td class="tg-yw4l"><a href="https://github.com/tticoin/AntonymDetection">AntonymDetection</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">41</td>
	  <td class="tg-6k2t"></td><!-- sense -->
	  <td class="tg-6k2t"></td><!-- sentence -->
	  <td class="tg-6k2t"></td><!-- retrofitting -->
	  <td class="tg-6k2t"></td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t">o</td><!-- others -->
	  <td class="tg-6k2t">Justin Gilmer, Luke Metz, Fartash Faghri, Samuel S. Schoenholz, Maithra Raghu, Martin Wattenberg, and Ian Goodfellow</td>
	  <td class="tg-6k2t"><a href="">Adversarial Spheres</a></td>
	  <td class="tg-6k2t">arXiv</td>
	  <td class="tg-6k2t">2018</td>
	  <td class="tg-6k2t"></td>
	 </tr>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">42</td>
	  <td class="tg-yw4l"></td><!-- sense -->
	  <td class="tg-yw4l"></td><!-- sentence -->
	  <td class="tg-yw4l">o</td><!-- retrofitting -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td><!-- others -->
	  <td class="tg-yw4l">Glavaš, Goran, and Ivan Vulić</td>
	  <td class="tg-yw4l"><a href="http://aclweb.org/anthology/P18-1004">Explicit Retrofitting of Distributional Word Vectors</a></td>
	  <td class="tg-yw4l">ACL</td>
	  <td class="tg-yw4l">2018</td>
	  <td class="tg-yw4l"><a href="https://github.com/codogogo/explirefit">ExpliRefit</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">43</td>
	  <td class="tg-6k2t"></td><!-- sense -->
	  <td class="tg-6k2t"></td><!-- sentence -->
	  <td class="tg-6k2t"></td><!-- retrofitting -->
	  <td class="tg-6k2t"></td><!-- Chinese -->
	  <td class="tg-6k2t">o</td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td><!-- others -->
	  <td class="tg-6k2t">Haochen Chen, Bryan Perozzi, Rami Al-Rfou, and Steven Skiena</td>
	  <td class="tg-6k2t"><a href="https://arxiv.org/pdf/1808.02590.pdf">A Tutorial on Network Embeddings</a></td>
	  <td class="tg-6k2t">arXiv</td>
	  <td class="tg-6k2t">2018</td>
	  <td class="tg-6k2t"></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">44</td>
	  <td class="tg-yw4l"></td><!-- sense -->
	  <td class="tg-yw4l"></td><!-- sentence -->
	  <td class="tg-yw4l"></td><!-- retrofitting -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td><!-- others -->
	  <td class="tg-yw4l">Mohammad, Saif, Bonnie Dorr, and Graeme Hirst</td>
	  <td class="tg-yw4l"><a href="https://pdfs.semanticscholar.org/71cd/ebf873055f4295e3252b90d5cf11423b2cfc.pdf">Computing word-pair antonymy</a></td>
	  <td class="tg-yw4l">EMNLP</td>
	  <td class="tg-yw4l">2008</td>
	  <td class="tg-yw4l"><a href=""></a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">45</td>
	  <td class="tg-6k2t"></td><!-- sense -->
	  <td class="tg-6k2t">o</td><!-- sentence -->
	  <td class="tg-6k2t"></td><!-- retrofitting -->
	  <td class="tg-6k2t"></td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td><!-- others -->
	  <td class="tg-6k2t">Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer</td>
	  <td class="tg-6k2t"><a href="https://arxiv.org/abs/1802.05365">Deep contextualized word representations</a></td>
	  <td class="tg-6k2t">NAACL</td>
	  <td class="tg-6k2t">2018</td>
	  <td class="tg-6k2t"><a href="https://allennlp.org/elmo">ELMo</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">46</td>
	  <td class="tg-yw4l"></td><!-- sense -->
	  <td class="tg-yw4l"></td><!-- sentence -->
	  <td class="tg-yw4l">o</td><!-- retrofitting -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td><!-- others -->
	  <td class="tg-yw4l">Lengerich, Benjamin J., Andrew L. Maas, and Christopher Potts</td>
	  <td class="tg-yw4l"><a href="https://arxiv.org/pdf/1708.00112.pdf">Retrofitting Distributional Embeddings to Knowledge Graphs with Functional Relations</a></td>
	  <td class="tg-yw4l">COLING</td>
	  <td class="tg-yw4l">2018</td>
	  <td class="tg-yw4l"><a href="https://github.com/roamanalytics/roamresearch/tree/master/Papers/Retrofitting">FR-Retrofitting</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">47</td>
	  <td class="tg-6k2t"></td><!-- sense -->
	  <td class="tg-6k2t"></td><!-- sentence -->
	  <td class="tg-6k2t"></td><!-- retrofitting -->
	  <td class="tg-6k2t"></td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td><!-- others -->
	  <td class="tg-6k2t">Pilehvar, Mohammad Taher and Kartsaklis, Dimitri and Prokhorov, Victor and Collier, Nigel</td>
	  <td class="tg-6k2t"><a href="https://pilehvar.github.io/card-660/Card-660.pdf">Card-660: Cambridge Rare Word Dataset -- a Reliable Benchmark for Infrequent Word Representation Models.</a></td>
	  <td class="tg-6k2t">EMNLP</td>
	  <td class="tg-6k2t">2018</td>
	  <td class="tg-6k2t"><a href="https://pilehvar.github.io/card-660/">Card-660</a></td>
	 </tr>
	 <tr>
	  <td class="tg-yw4l">48</td>
	  <td class="tg-yw4l"></td><!-- sense -->
	  <td class="tg-yw4l"></td><!-- sentence -->
	  <td class="tg-yw4l"></td><!-- retrofitting -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Network Embedding -->
	  <td class="tg-yw4l"></td><!-- others -->
	  <td class="tg-yw4l">Nigel Collier and Mohammad Taher Pilehvar</td>
	  <td class="tg-yw4l"><a href="http://www.pilevar.com/taher/pubs/Pilehvar_Collier_EACL2017.pdf">Inducing Representations for Rare Words by Leveraging Lexical Resources</a></td>
	  <td class="tg-yw4l">EACL</td>
	  <td class="tg-yw4l">2017</td>
	  <td class="tg-yw4l"><a href="https://pilehvar.github.io/embeducer/">embeducer</a></td>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">49</td>
	  <td class="tg-6k2t"></td><!-- sense -->
	  <td class="tg-6k2t"></td><!-- sentence -->
	  <td class="tg-6k2t"></td><!-- retrofitting -->
	  <td class="tg-6k2t"></td><!-- Chinese -->
	  <td class="tg-6k2t">o</td><!-- Network Embedding -->
	  <td class="tg-6k2t"></td><!-- others -->
	  <td class="tg-6k2t">Mingjie Sun, Jian Tang, Huichen Li, Bo Li, Chaowei Xiao, Yao Chen, Dawn Song</td>
	  <td class="tg-6k2t"><a href="https://arxiv.org/pdf/1810.12881.pdf">Data Poisoning Attack against Unsupervised Node Embedding Methods</a></td>
	  <td class="tg-6k2t">arXiv</td>
	  <td class="tg-6k2t">2018</td>
	  <td class="tg-6k2t"></td>
	 </tr>
	</table>
	<script type="text/javascript" charset="utf-8">var TgTableSort=window.TgTableSort||function(n,t){"use strict";function r(n,t){for(var e=[],o=n.childNodes,i=0;i<o.length;++i){var u=o[i];if("."==t.substring(0,1)){var a=t.substring(1);f(u,a)&&e.push(u)}else u.nodeName.toLowerCase()==t&&e.push(u);var c=r(u,t);e=e.concat(c)}return e}function e(n,t){var e=[],o=r(n,"tr");return o.forEach(function(n){var o=r(n,"td");t>=0&&t<o.length&&e.push(o[t])}),e}function o(n){return n.textContent||n.innerText||""}function i(n){return n.innerHTML||""}function u(n,t){var r=e(n,t);return r.map(o)}function a(n,t){var r=e(n,t);return r.map(i)}function c(n){var t=n.className||"";return t.match(/\S+/g)||[]}function f(n,t){return-1!=c(n).indexOf(t)}function s(n,t){f(n,t)||(n.className+=" "+t)}function d(n,t){if(f(n,t)){var r=c(n),e=r.indexOf(t);r.splice(e,1),n.className=r.join(" ")}}function v(n){d(n,L),d(n,E)}function l(n,t,e){r(n,"."+E).map(v),r(n,"."+L).map(v),e==T?s(t,E):s(t,L)}function g(n){return function(t,r){var e=n*t.str.localeCompare(r.str);return 0==e&&(e=t.index-r.index),e}}function h(n){return function(t,r){var e=+t.str,o=+r.str;return e==o?t.index-r.index:n*(e-o)}}function m(n,t,r){var e=u(n,t),o=e.map(function(n,t){return{str:n,index:t}}),i=e&&-1==e.map(isNaN).indexOf(!0),a=i?h(r):g(r);return o.sort(a),o.map(function(n){return n.index})}function p(n,t,r,o){for(var i=f(o,E)?N:T,u=m(n,r,i),c=0;t>c;++c){var s=e(n,c),d=a(n,c);s.forEach(function(n,t){n.innerHTML=d[u[t]]})}l(n,o,i)}function x(n,t){var r=t.length;t.forEach(function(t,e){t.addEventListener("click",function(){p(n,r,e,t)}),s(t,"tg-sort-header")})}var T=1,N=-1,E="tg-sort-asc",L="tg-sort-desc";return function(t){var e=n.getElementById(t),o=r(e,"tr"),i=o.length>0?r(o[0],"td"):[];0==i.length&&(i=r(o[0],"th"));for(var u=1;u<o.length;++u){var a=r(o[u],"td");if(a.length!=i.length)return}x(e,i)}}(document);document.addEventListener("DOMContentLoaded",function(n){TgTableSort("tg-Jb0Jr")});</script>

	<h4>Collections</h4>
	<p>
	(New) <a href="https://github.com/Eilene/spatio-temporal-paper-list">Spatio-temporal modeling 論文列表（主要是graph convolution相關）</a>
	<br>
	(New) <a href="https://montrealartificialintelligence.com/academy/#Deep-Meta-Learning">Montréal Artificial Intelligence</a>
	<br>
	(New) <a href="https://github.com/chihming/awesome-network-embedding">awesome-network-embedding</a>
	<br>
	(New) <a href="https://github.com/thunlp/OpenNE">OpenNE: An open source toolkit for Network Embedding</a>
	<br>
	<a href="https://github.com/Hironsan/awesome-embedding-models">awesome-embedding-models</a>
	<br>
	<a href="https://github.com/keon/awesome-nlp">awesome-nlp</a>
	<br>
	<a href="https://github.com/josephmisiti/awesome-machine-learning">Awesome Machine Learning</a>
	<br>
	<a href="https://github.com/thunlp/NRLpapers">Must-read papers on network representation learning network embedding</a>
	<br>
	<a href="https://github.com/MaxwellRebo/awesome-2vec">awesome-2vec</a>
	<br>
	<a href="https://github.com/fchollet/deep-learning-with-python-notebooks">Deep Learning with Python </a>
	<br>
	</p>

	<h4>Library</h4>
	<p>
	(new) <a href="https://github.com/plasticityai/magnitude">Magnitude: a fast, simple vector embedding utility library</a>
	<br>
	</p>

	<h4>paper</h4>
	<p>
	(new) <a href="https://sci-hub.tw/">sci-hub</a>
	<br>
	</p>
	
	<h4>API</h4>
	<p>
	<a href="https://github.com/Manwholikespie/thesaurus-api">An api for thesaurus.com</a>
	<br>
	</p>

	<h4>Datasets</h4>
	<p>
	(new) <a href="https://pilehvar.github.io/card-660/">Card-660</a>
	<br>
	<a href="https://staff.fnwi.uva.nl/e.bruni/MEN">MEN</a>
	<br>
	<a href="http://alfonseca.org/eng/research/wordsim353.html">WordSim353</a>
	<br>
	<a href="http://www.cl.cam.ac.uk/~fh295/simlex.html">SimLex-999</a>
	<br>
	<a href="http://www2.mta.ac.il/~gideon/mturk771.html">Mturk-771</a>
	<br>
	<a href="http://www.kiraradinsky.com/Datasets.html">Mturk-287</a>
	<br>
	<a href="https://nlp.stanford.edu/~lmthang/morphoNLM/">Rare Word (RW)</a>
	<br>
	<a href="https://dl.acm.org/citation.cfm?id=365657">RG65</a>
	<br>
	<a href="https://www.researchgate.net/profile/David_Powers2/publication/257946337_Verb_similarity_on_the_taxonomy_of_WordNet_-_dataset/data/02e7e5266fe99269cc000000/200601-GWC-130verbpairs.txt">YP130</a>
	</p>

	<h4>Course</h4>
	<p>
	(New) <a href="http://www.phontron.com/class/nn4nlp2017/index.html">Neural Networks for NLP</a> CMU CS 11-747, Fall 2017
	<br>
	(New) <a href="https://medium.com/@kuanchen_981/course-note-convex-optimization-cmu-fall-2016-15-standford-2009-14c394f16db2">Course Note: Convex optimization</a> (CMU Fall 2016,15 + Standford 2009)
	<br>
	 
	</p>

	<h4>Books</h4>
	<p>
	(New) <a href="https://nbviewer.jupyter.org/github/ptwobrussell/Mining-the-Social-Web-2nd-Edition/tree/master/ipynb/">Mining the Social Web</a> 2nd Edition
	<br>

	</p>


	<h4>Our</h4>
	<p>
	<a href="https://github.com/y95847frank/Joint-Retrofitting">Joint-Retrofitting</a>
	<br>
	<a href="https://github.com/y95847frank/GenSense">GenSense</a>
	</p>
	</table>
</div>

<div id="Learn" class="tabcontent">
	<table width="700px" cellpadding="2" cellspacing="0" class="TG" style="word-break:break-all;">

	<!--//產生方法:
		1. 進入 https://www.tablesgenerator.com/html_tables 
		2. 複製ods檔案整理的結果(最後一行包含a herf資訊)
		3. 貼上
		4. 選擇Theme
		5. 下面要勾選Enable table sorting
		6. 產生出來的html程式碼要做以下處理:
		  取代"&lt;" -> "<" (小於符號)
		  取代"&gt;" -> ">" (大於符號)
		  取代"<br>" -> "" (空字串)
		7. 貼到這裡
		8. 放到...\word_representation\eric890006.github.io
		註:按照以上步驟，ods上面的姓名特殊字元不用處理
	//-->

	<style type="text/css">
	.tg {border-collapse:collapse;border-spacing:0;border-color:#aabcfe;}
	.tg td{font-family:Arial, sans-serif;font-size:14px;padding:3px 1px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#aabcfe;color:#669;background-color:#e8edff;border-top-width:1px;border-bottom-width:1px;}
	.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:3px 1px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#aabcfe;color:#039;background-color:#b9c9fe;border-top-width:1px;border-bottom-width:1px;}
	.tg .tg-vn4c{background-color:#D2E4FC}
	.tg .tg-yw4l{vertical-align:top}
	.tg .tg-6k2t{background-color:#D2E4FC;vertical-align:top}
	th.tg-sort-header::-moz-selection { background:transparent; }th.tg-sort-header::selection   { background:transparent; }th.tg-sort-header { cursor:pointer; }table th.tg-sort-header:after { content:''; float:right; margin-top:7px; border-width:0 4px 4px; border-style:solid; border-color:#404040 transparent; visibility:hidden; }table th.tg-sort-header:hover:after { visibility:visible; }table th.tg-sort-desc:after,table th.tg-sort-asc:after,table th.tg-sort-asc:hover:after { visibility:visible; opacity:0.4; }table th.tg-sort-desc:after { border-bottom:none; border-width:4px 4px 0; }

	body {font-family: sans-serif;background-color: #f7f6eb;color: #333;}
	#mainContainer {width: 900px;margin: auto;}
	h2 {text-align: center;}
	p, blockquote {margin-left: 50px; text-align: justify}
	ul {display: block; margin-left: 50px}
	h4 {text-align: left;}
	</style>
	<h4>Click the Labels to sort.</h4>
	<table id="tg-Jb0Jr2" class="tg">
	 <tr>
	  <th class="tg-031e">預設</th>
	  <th class="tg-031e">機器</th>
	  <th class="tg-031e">自然</th>
	  <th class="tg-yw4l">尤尼斯</th>
	  <th class="tg-yw4l">資料</th>
	  <th class="tg-yw4l">課程</th>
	  <th class="tg-yw4l">工作</th>
	  <th class="tg-yw4l">中文</th>
	  <th class="tg-yw4l">其他</th>
	  <th class="tg-yw4l">網站</th>
	  <th class="tg-yw4l">註</th>
	 </tr>
	 <tr>
	  <td class="tg-6k2t">01</td>
	  <td class="tg-6k2t"></td><!-- Machine Learning -->
	  <td class="tg-6k2t">o</td><!-- NLP -->
	  <td class="tg-6k2t"></td><!-- LINUX -->
	  <td class="tg-6k2t"></td><!-- Dataset -->
	  <td class="tg-6k2t"></td><!-- 課程 -->
	  <td class="tg-6k2t"></td><!-- Work -->
	  <td class="tg-6k2t">o</td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Others -->
	  <td class="tg-6k2t"><a href="https://gist.github.com/luw2007/6016931">詞性標記</a></td><!-- Site -->
	  <td class="tg-6k2t">包含 ICTPOS3.0詞性標記集、ICTCLAS 漢語詞性標註集、jieba 字典中出現的詞性、simhash 中可以忽略的部分詞性</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-yw4l">02</td>
	  <td class="tg-yw4l"></td><!-- Machine Learning -->
	  <td class="tg-yw4l">o</td><!-- NLP -->
	  <td class="tg-yw4l"></td><!-- LINUX -->
	  <td class="tg-yw4l"></td><!-- Dataset -->
	  <td class="tg-yw4l"></td><!-- 課程 -->
	  <td class="tg-yw4l"></td><!-- Work -->
	  <td class="tg-yw4l">o</td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Others -->
	  <td class="tg-yw4l"><a href="https://github.com/fxsjy/jieba/issues/14">增強歧義糾錯</a></td><!-- Site -->
	  <td class="tg-yw4l">通過用戶自定義詞典來增強歧義糾錯能力</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-6k2t">03</td>
	  <td class="tg-6k2t"></td><!-- Machine Learning -->
	  <td class="tg-6k2t">o</td><!-- NLP -->
	  <td class="tg-6k2t"></td><!-- LINUX -->
	  <td class="tg-6k2t"></td><!-- Dataset -->
	  <td class="tg-6k2t"></td><!-- 課程 -->
	  <td class="tg-6k2t"></td><!-- Work -->
	  <td class="tg-6k2t">o</td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Others -->
	  <td class="tg-6k2t"><a href="http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%95%E5%85%A8%E6%96%87%E6%96%87%E6%A1%A3">中文分詞入門之字標註法全文文檔</a></td><!-- Site -->
	  <td class="tg-6k2t"></td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-yw4l">04</td>
	  <td class="tg-yw4l">o</td><!-- Machine Learning -->
	  <td class="tg-yw4l">o</td><!-- NLP -->
	  <td class="tg-yw4l"></td><!-- LINUX -->
	  <td class="tg-yw4l"></td><!-- Dataset -->
	  <td class="tg-yw4l"></td><!-- 課程 -->
	  <td class="tg-yw4l"></td><!-- Work -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Others -->
	  <td class="tg-yw4l"><a href="https://www.csie.ntu.edu.tw/~cjlin/libshorttext/">LibShortText</a></td><!-- Site -->
	  <td class="tg-yw4l">A Library for Short-text Classification and Analysis</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-6k2t">05</td>
	  <td class="tg-6k2t"></td><!-- Machine Learning -->
	  <td class="tg-6k2t">o</td><!-- NLP -->
	  <td class="tg-6k2t"></td><!-- LINUX -->
	  <td class="tg-6k2t"></td><!-- Dataset -->
	  <td class="tg-6k2t"></td><!-- 課程 -->
	  <td class="tg-6k2t"></td><!-- Work -->
	  <td class="tg-6k2t">o</td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Others -->
	  <td class="tg-6k2t"><a href="https://zh.wikipedia.org/wiki/%E6%A0%BC_(%E8%AF%AD%E6%B3%95)">格 (語法) wiki</a></td><!-- Site -->
	  <td class="tg-6k2t">也叫語義格，是名詞或代名詞因語義角色不同而變化。</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-yw4l">06</td>
	  <td class="tg-yw4l">o</td><!-- Machine Learning -->
	  <td class="tg-yw4l">o</td><!-- NLP -->
	  <td class="tg-yw4l"></td><!-- LINUX -->
	  <td class="tg-yw4l"></td><!-- Dataset -->
	  <td class="tg-yw4l">o</td><!-- 課程 -->
	  <td class="tg-yw4l"></td><!-- Work -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Others -->
	  <td class="tg-yw4l"><a href="https://web.stanford.edu/class/cs224u/">CS224U: Natural Language Understanding</a></td><!-- Site -->
	  <td class="tg-yw4l">Stanford, Bill MacCartney, [Distributed representations, Supervised sentiment analysis, Relation extraction, Natural language inference, Semantic parsing, Grounded language understanding]</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-6k2t">07</td>
	  <td class="tg-6k2t"></td><!-- Machine Learning -->
	  <td class="tg-6k2t">o</td><!-- NLP -->
	  <td class="tg-6k2t"></td><!-- LINUX -->
	  <td class="tg-6k2t"></td><!-- Dataset -->
	  <td class="tg-6k2t">o</td><!-- 課程 -->
	  <td class="tg-6k2t"></td><!-- Work -->
	  <td class="tg-6k2t">o</td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Others -->
	  <td class="tg-6k2t"><a href="https://web.stanford.edu/class/cs124/">CS 124: From Languages to Information</a></td><!-- Site -->
	  <td class="tg-6k2t">Stanford, Dan Jurafsky, [Edit Distance, Language Modeling, Spelling Correction/Noisy Channel, Naive Bayes/Text Classification, Sentiment Analysis, Information Retrieval, Relation Extraction, Question Answering, Chat Bots, Social Meaning, Recommender systems, Vector Semantics/Neural Embeddings/Word2Vec, Web graphs, Links, and PageRank, Social Networks]</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-yw4l">08</td>
	  <td class="tg-yw4l">o</td><!-- Machine Learning -->
	  <td class="tg-yw4l">o</td><!-- NLP -->
	  <td class="tg-yw4l"></td><!-- LINUX -->
	  <td class="tg-yw4l"></td><!-- Dataset -->
	  <td class="tg-yw4l"></td><!-- 課程 -->
	  <td class="tg-yw4l"></td><!-- Work -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Others -->
	  <td class="tg-yw4l"><a href="http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/">Machine Learning :: Text feature extraction (tf-idf)</a></td><!-- Site -->
	  <td class="tg-yw4l">Short introduction to Vector Space Model (VSM)</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-6k2t">09</td>
	  <td class="tg-6k2t"></td><!-- Machine Learning -->
	  <td class="tg-6k2t">o</td><!-- NLP -->
	  <td class="tg-6k2t"></td><!-- LINUX -->
	  <td class="tg-6k2t"></td><!-- Dataset -->
	  <td class="tg-6k2t"></td><!-- 課程 -->
	  <td class="tg-6k2t"></td><!-- Work -->
	  <td class="tg-6k2t">o</td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Others -->
	  <td class="tg-6k2t"><a href="https://g0v.hackpad.tw/ep/pad/static/aco0Hxp4IEz">中文處理工具簡介</a></td><!-- Site -->
	  <td class="tg-6k2t">中研院CKIP parser, stanford parser, mmseg 斷詞, SCWS 中文分词, NLTK, CNLP, 結巴中文分詞（簡中）, FudanNLP（簡中）, Glove, OpenCC繁簡轉換, ansj簡體斷詞, 國教院分詞系統, cjknife, Unicode Normalization, JIEBA 結巴中文斷詞</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-yw4l">10</td>
	  <td class="tg-yw4l"></td><!-- Machine Learning -->
	  <td class="tg-yw4l">o</td><!-- NLP -->
	  <td class="tg-yw4l"></td><!-- LINUX -->
	  <td class="tg-yw4l">o</td><!-- Dataset -->
	  <td class="tg-yw4l"></td><!-- 課程 -->
	  <td class="tg-yw4l"></td><!-- Work -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Others -->
	  <td class="tg-yw4l"><a href="http://storage.googleapis.com/books/ngrams/books/datasetsv2.html">Google Books Ngram Viewer</a></td><!-- Site -->
	  <td class="tg-yw4l"></td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-6k2t">11</td>
	  <td class="tg-6k2t"></td><!-- Machine Learning -->
	  <td class="tg-6k2t">o</td><!-- NLP -->
	  <td class="tg-6k2t"></td><!-- LINUX -->
	  <td class="tg-6k2t">o</td><!-- Dataset -->
	  <td class="tg-6k2t"></td><!-- 課程 -->
	  <td class="tg-6k2t"></td><!-- Work -->
	  <td class="tg-6k2t">o</td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Others -->
	  <td class="tg-6k2t"><a href="http://ir.itc.ntnu.edu.tw/lre/nlptea14cfl.htm">NLPTEA 2014 Shared Task</a></td><!-- Site -->
	  <td class="tg-6k2t">Chinese as a Foreign Language</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-yw4l">12</td>
	  <td class="tg-yw4l"></td><!-- Machine Learning -->
	  <td class="tg-yw4l">o</td><!-- NLP -->
	  <td class="tg-yw4l"></td><!-- LINUX -->
	  <td class="tg-yw4l">o</td><!-- Dataset -->
	  <td class="tg-yw4l"></td><!-- 課程 -->
	  <td class="tg-yw4l"></td><!-- Work -->
	  <td class="tg-yw4l">o</td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Others -->
	  <td class="tg-yw4l"><a href="http://ir.itc.ntnu.edu.tw/lre/sighan7csc.html">SIGHAN 2013 Bake-off</a></td><!-- Site -->
	  <td class="tg-yw4l">Chinese Spelling Check Task</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-6k2t">13</td>
	  <td class="tg-6k2t"></td><!-- Machine Learning -->
	  <td class="tg-6k2t">o</td><!-- NLP -->
	  <td class="tg-6k2t"></td><!-- LINUX -->
	  <td class="tg-6k2t"></td><!-- Dataset -->
	  <td class="tg-6k2t"></td><!-- 課程 -->
	  <td class="tg-6k2t"></td><!-- Work -->
	  <td class="tg-6k2t"></td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Others -->
	  <td class="tg-6k2t"><a href="http://aclweb.org/anthology//">ACL Anthology</a></td><!-- Site -->
	  <td class="tg-6k2t">A Digital Archive of Research Papers in Computational Linguistics</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-yw4l">14</td>
	  <td class="tg-yw4l"></td><!-- Machine Learning -->
	  <td class="tg-yw4l">o</td><!-- NLP -->
	  <td class="tg-yw4l"></td><!-- LINUX -->
	  <td class="tg-yw4l">o</td><!-- Dataset -->
	  <td class="tg-yw4l"></td><!-- 課程 -->
	  <td class="tg-yw4l"></td><!-- Work -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Others -->
	  <td class="tg-yw4l"><a href="http://www.cad.zju.edu.cn/home/dengcai/Data/TextData.html">Text datasets in matlab format</a></td><!-- Site -->
	  <td class="tg-yw4l">Top 30 categories in TDT2, All categories in TDT2, All categories in Reuters21578, 20 Newsgroups (version 1), 20 Newsgroups (version 2), Selected 4 categories in RCV1 </td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-6k2t">15</td>
	  <td class="tg-6k2t"></td><!-- Machine Learning -->
	  <td class="tg-6k2t">o</td><!-- NLP -->
	  <td class="tg-6k2t"></td><!-- LINUX -->
	  <td class="tg-6k2t">o</td><!-- Dataset -->
	  <td class="tg-6k2t"></td><!-- 課程 -->
	  <td class="tg-6k2t"></td><!-- Work -->
	  <td class="tg-6k2t"></td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Others -->
	  <td class="tg-6k2t"><a href="http://mattmahoney.net/dc/textdata.html">The test data for the Large Text Compression Benchmark</a></td><!-- Site -->
	  <td class="tg-6k2t">10^9 bytes of the English Wikipedia dump on Mar. 3, 2006</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-yw4l">16</td>
	  <td class="tg-yw4l">o</td><!-- Machine Learning -->
	  <td class="tg-yw4l">o</td><!-- NLP -->
	  <td class="tg-yw4l"></td><!-- LINUX -->
	  <td class="tg-yw4l"></td><!-- Dataset -->
	  <td class="tg-yw4l">o</td><!-- 課程 -->
	  <td class="tg-yw4l"></td><!-- Work -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Others -->
	  <td class="tg-yw4l"><a href="http://ttic.uchicago.edu/~kgimpel/teaching/31210/lectures.html">TTIC 31210: Advanced Natural Language Processing lectures</a></td><!-- Site -->
	  <td class="tg-yw4l">University of Chicago, [Word Embeddings, Seq2Seq Modeling/Sentence Embeddings, Structured Prediction with Neural Networks in Speech Recognition, Seq2Seq Modeling/Attention, Neural Machine Translation, Neural Machine Translation (NMT), Inference in Bayesian NLP, Unsupervised NLP, Bayesian Nonparametrics in NLP, Structured Prediction in NLP, Syntactic and Semantic Formalisms]</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-6k2t">17</td>
	  <td class="tg-6k2t">o</td><!-- Machine Learning -->
	  <td class="tg-6k2t">o</td><!-- NLP -->
	  <td class="tg-6k2t"></td><!-- LINUX -->
	  <td class="tg-6k2t"></td><!-- Dataset -->
	  <td class="tg-6k2t">o</td><!-- 課程 -->
	  <td class="tg-6k2t"></td><!-- Work -->
	  <td class="tg-6k2t"></td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Others -->
	  <td class="tg-6k2t"><a href="http://ttic.uchicago.edu/~kgimpel/teaching/31190/lectures.html">TTIC 31190: Natural Language Processing lectures</a></td><!-- Site -->
	  <td class="tg-6k2t">University of Chicago, [Text Classification, Lexical Semantics, Word Vectors, Language Modeling, Sequence Models, Inference in Structured Prediction, Neural Network for NLP, RNN/CNN in NLP, Syntax and Parsing, Dependency Grammar/Dependency Parsing, Computational Semantics, Machine Translation]</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-yw4l">18</td>
	  <td class="tg-yw4l">o</td><!-- Machine Learning -->
	  <td class="tg-yw4l"></td><!-- NLP -->
	  <td class="tg-yw4l"></td><!-- LINUX -->
	  <td class="tg-yw4l"></td><!-- Dataset -->
	  <td class="tg-yw4l"></td><!-- 課程 -->
	  <td class="tg-yw4l"></td><!-- Work -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Others -->
	  <td class="tg-yw4l"><a href="http://fcamel-fc.blogspot.com/2010/03/machine-learning.html">我學 Machine Learning 的方法</a></td><!-- Site -->
	  <td class="tg-yw4l">讀 Data mining 的書, 讀國外大學的授課講義, 讀 Wikipedia, 讀經典課本</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-6k2t">19</td>
	  <td class="tg-6k2t">o</td><!-- Machine Learning -->
	  <td class="tg-6k2t"></td><!-- NLP -->
	  <td class="tg-6k2t"></td><!-- LINUX -->
	  <td class="tg-6k2t"></td><!-- Dataset -->
	  <td class="tg-6k2t">o</td><!-- 課程 -->
	  <td class="tg-6k2t"></td><!-- Work -->
	  <td class="tg-6k2t">o</td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Others -->
	  <td class="tg-6k2t"><a href="http://www.cmlab.csie.ntu.edu.tw/~cyy/learning/">Machine Learning for Graphics, Vision and Multimedia</a></td><!-- Site -->
	  <td class="tg-6k2t">PCA, PCA missing data, Robust PCA, ISOMAP & LLE, LDA, LDA applications, LPP, SVM, SVR, RVM, Ensemble Learning, AdaBoost binary/extensions/applications, Graphical Model, low-level learning, EM, Variational Learning</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-yw4l">20</td>
	  <td class="tg-yw4l">o</td><!-- Machine Learning -->
	  <td class="tg-yw4l"></td><!-- NLP -->
	  <td class="tg-yw4l"></td><!-- LINUX -->
	  <td class="tg-yw4l"></td><!-- Dataset -->
	  <td class="tg-yw4l">o</td><!-- 課程 -->
	  <td class="tg-yw4l"></td><!-- Work -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Others -->
	  <td class="tg-yw4l"><a href="http://cs229.stanford.edu/">CS229: Machine Learning</a></td><!-- Site -->
	  <td class="tg-yw4l">Stanford, Autumn 2017, Dan Boneh, Andrew Ng. </td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-6k2t">21</td>
	  <td class="tg-6k2t">o</td><!-- Machine Learning -->
	  <td class="tg-6k2t"></td><!-- NLP -->
	  <td class="tg-6k2t"></td><!-- LINUX -->
	  <td class="tg-6k2t"></td><!-- Dataset -->
	  <td class="tg-6k2t">o</td><!-- 課程 -->
	  <td class="tg-6k2t"></td><!-- Work -->
	  <td class="tg-6k2t">o</td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Others -->
	  <td class="tg-6k2t"><a href="http://zhfuzh.blog.163.com/blog/#m=0&t=1&c=fks_084070087086082066085084084095085082084070087095085075083">統計學習初探索</a></td><!-- Site -->
	  <td class="tg-6k2t">線性分類器, Basis Expansion, Kernel Smoothing Methods, Model Selection and Model Assessment, Model Inference and Average (EM Algorithm), Additive Models and Trees, Artificial Neural Network, Support Vector Machine, Prototype Methods and KNN, Supervised VS Unsupervised, Association Rule, Dimensionality Reduction</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-yw4l">22</td>
	  <td class="tg-yw4l">o</td><!-- Machine Learning -->
	  <td class="tg-yw4l"></td><!-- NLP -->
	  <td class="tg-yw4l"></td><!-- LINUX -->
	  <td class="tg-yw4l"></td><!-- Dataset -->
	  <td class="tg-yw4l">o</td><!-- 課程 -->
	  <td class="tg-yw4l"></td><!-- Work -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Others -->
	  <td class="tg-yw4l"><a href="http://work.caltech.edu/telecourse.html">Learning From Data</a></td><!-- Site -->
	  <td class="tg-yw4l">Caltech, Yaser Abu-Mostafa. [The Learning Problem, Is Learning Feasible?, The Linear Model I, Error and Noise, Training versus Testing, Theory of Generalization, The VC Dimension, Bias-Variance Tradeoff, The Linear Model II, Neural Networks, Overfitting, Regularization, Validation, Support Vector Machines, Kernel Methods, Radial Basis Functions, Three Learning Principles, Epilogue]</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-6k2t">23</td>
	  <td class="tg-6k2t">o</td><!-- Machine Learning -->
	  <td class="tg-6k2t"></td><!-- NLP -->
	  <td class="tg-6k2t"></td><!-- LINUX -->
	  <td class="tg-6k2t"></td><!-- Dataset -->
	  <td class="tg-6k2t">o</td><!-- 課程 -->
	  <td class="tg-6k2t"></td><!-- Work -->
	  <td class="tg-6k2t"></td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Others -->
	  <td class="tg-6k2t"><a href="http://web.stanford.edu/class/ee364a/">EE364a: Convex Optimization I</a></td><!-- Site -->
	  <td class="tg-6k2t">Stanford, Reese Pathak. [Convex sets, Convex functions, Convex optimization problems, Duality, Approximation and fitting, Statistical estimation, Geometric problems, Numerical linear algebra background, Unconstrained minimization, Equality constrained minimization, Interior-point methods]</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-yw4l">24</td>
	  <td class="tg-yw4l">o</td><!-- Machine Learning -->
	  <td class="tg-yw4l"></td><!-- NLP -->
	  <td class="tg-yw4l"></td><!-- LINUX -->
	  <td class="tg-yw4l"></td><!-- Dataset -->
	  <td class="tg-yw4l">o</td><!-- 課程 -->
	  <td class="tg-yw4l"></td><!-- Work -->
	  <td class="tg-yw4l"></td><!-- Chinese -->
	  <td class="tg-yw4l"></td><!-- Others -->
	  <td class="tg-yw4l"><a href="https://web.stanford.edu/class/ee364b/">EE364b: Convex Optimization II</a> <a href="https://see.stanford.edu/Course/EE364B">Website2</a></td><!-- Site -->
	  <td class="tg-yw4l">Stanford, John Duchi. [Subgradient methods, Localization methods, Decomposition and distributed optimization, Proximal and operator splitting methods, Conjugate gradients, Nonconvex problems, Additional lecture notes]</td> <!-- Comment -->
	 </tr>
	 <tr>
	  <td class="tg-6k2t">23</td>
	  <td class="tg-6k2t">o</td><!-- Machine Learning -->
	  <td class="tg-6k2t"></td><!-- NLP -->
	  <td class="tg-6k2t"></td><!-- LINUX -->
	  <td class="tg-6k2t"></td><!-- Dataset -->
	  <td class="tg-6k2t"></td><!-- 課程 -->
	  <td class="tg-6k2t"></td><!-- Work -->
	  <td class="tg-6k2t"></td><!-- Chinese -->
	  <td class="tg-6k2t"></td><!-- Others -->
	  <td class="tg-6k2t"><a href="http://web.stanford.edu/~boyd/papers/admm_distr_stats.html">Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers</a></td><!-- Site -->
	  <td class="tg-6k2t">Foundations and Trends in Machine Learning, 3(1):1–122, 2011.</td> <!-- Comment -->
	 </tr>
	 
	</table>
	<script type="text/javascript" charset="utf-8">var TgTableSort=window.TgTableSort||function(n,t){"use strict";function r(n,t){for(var e=[],o=n.childNodes,i=0;i<o.length;++i){var u=o[i];if("."==t.substring(0,1)){var a=t.substring(1);f(u,a)&&e.push(u)}else u.nodeName.toLowerCase()==t&&e.push(u);var c=r(u,t);e=e.concat(c)}return e}function e(n,t){var e=[],o=r(n,"tr");return o.forEach(function(n){var o=r(n,"td");t>=0&&t<o.length&&e.push(o[t])}),e}function o(n){return n.textContent||n.innerText||""}function i(n){return n.innerHTML||""}function u(n,t){var r=e(n,t);return r.map(o)}function a(n,t){var r=e(n,t);return r.map(i)}function c(n){var t=n.className||"";return t.match(/\S+/g)||[]}function f(n,t){return-1!=c(n).indexOf(t)}function s(n,t){f(n,t)||(n.className+=" "+t)}function d(n,t){if(f(n,t)){var r=c(n),e=r.indexOf(t);r.splice(e,1),n.className=r.join(" ")}}function v(n){d(n,L),d(n,E)}function l(n,t,e){r(n,"."+E).map(v),r(n,"."+L).map(v),e==T?s(t,E):s(t,L)}function g(n){return function(t,r){var e=n*t.str.localeCompare(r.str);return 0==e&&(e=t.index-r.index),e}}function h(n){return function(t,r){var e=+t.str,o=+r.str;return e==o?t.index-r.index:n*(e-o)}}function m(n,t,r){var e=u(n,t),o=e.map(function(n,t){return{str:n,index:t}}),i=e&&-1==e.map(isNaN).indexOf(!0),a=i?h(r):g(r);return o.sort(a),o.map(function(n){return n.index})}function p(n,t,r,o){for(var i=f(o,E)?N:T,u=m(n,r,i),c=0;t>c;++c){var s=e(n,c),d=a(n,c);s.forEach(function(n,t){n.innerHTML=d[u[t]]})}l(n,o,i)}function x(n,t){var r=t.length;t.forEach(function(t,e){t.addEventListener("click",function(){p(n,r,e,t)}),s(t,"tg-sort-header")})}var T=1,N=-1,E="tg-sort-asc",L="tg-sort-desc";return function(t){var e=n.getElementById(t),o=r(e,"tr"),i=o.length>0?r(o[0],"td"):[];0==i.length&&(i=r(o[0],"th"));for(var u=1;u<o.length;++u){var a=r(o[u],"td");if(a.length!=i.length)return}x(e,i)}}(document);document.addEventListener("DOMContentLoaded",function(n){TgTableSort("tg-Jb0Jr2")});</script>

	<h4>Collections</h4>

	</table>
</div>

<script>
function openCity(evt, cityName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(cityName).style.display = "block";
    evt.currentTarget.className += " active";
}
document.getElementById("defaultOpen").click();
</script>
     
</body>
</html> 
