<html>
<body>
<div align="center">
<div id="BbsShow"><meta http-equiv="content-type" content="text/html; charset=utf-8" />
<table width="700px" cellpadding="2" cellspacing="0" class="TG" style="word-break:break-all;">

<!--//產生方法:
	1. 進入 https://www.tablesgenerator.com/html_tables 
	2. 複製ods檔案整理的結果(最後一行包含a herf資訊)
	3. 貼上
	4. 選擇Theme
	5. 下面要勾選Enable table sorting
	6. 產生出來的html程式碼要做以下處理:
	  取代"&lt;" -> "<" (小於符號)
	  取代"&gt;" -> ">" (大於符號)
	  取代"<br>" -> "" (空字串)
	7. 貼到這裡
	8. 放到...\word_representation\eric890006.github.io
	註:按照以上步驟，ods上面的姓名特殊字元不用處理
//-->

<style type="text/css">
.tg {border-collapse:collapse;border-spacing:0;border-color:#aabcfe;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:3px 1px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#aabcfe;color:#669;background-color:#e8edff;border-top-width:1px;border-bottom-width:1px;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:3px 1px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#aabcfe;color:#039;background-color:#b9c9fe;border-top-width:1px;border-bottom-width:1px;}
.tg .tg-vn4c{background-color:#D2E4FC}
.tg .tg-yw4l{vertical-align:top}
.tg .tg-6k2t{background-color:#D2E4FC;vertical-align:top}
th.tg-sort-header::-moz-selection { background:transparent; }th.tg-sort-header::selection   { background:transparent; }th.tg-sort-header { cursor:pointer; }table th.tg-sort-header:after { content:''; float:right; margin-top:7px; border-width:0 4px 4px; border-style:solid; border-color:#404040 transparent; visibility:hidden; }table th.tg-sort-header:hover:after { visibility:visible; }table th.tg-sort-desc:after,table th.tg-sort-asc:after,table th.tg-sort-asc:hover:after { visibility:visible; opacity:0.4; }table th.tg-sort-desc:after { border-bottom:none; border-width:4px 4px 0; }</style>
<table id="tg-Jb0Jr" class="tg">
 <tr>
  <th class="tg-031e">預設</th>
  <th class="tg-031e">語意</th>
  <th class="tg-031e">句子</th>
  <th class="tg-yw4l">修正</th>
  <th class="tg-yw4l">中文</th>
  <th class="tg-yw4l">其他</th>
  <th class="tg-yw4l">AUTHORS</th>
  <th class="tg-yw4l">TITLE</th>
  <th class="tg-yw4l">CONFERENCE</th>
  <th class="tg-yw4l">YEAR</th>
  <th class="tg-yw4l">LINKS</th>
 </tr>
 <tr>
  <td class="tg-vn4c">01</td>
  <td class="tg-vn4c"></td>
  <td class="tg-vn4c"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">Jeffrey Pennington, Richard Socher, and Christopher D. Manning</td>
  <td class="tg-6k2t"><a href="https://www.aclweb.org/anthology/D14-1162">GloVe: Global Vectors for Word Representation</a></td>
  <td class="tg-6k2t">EMNLP</td>
  <td class="tg-6k2t">2014</td>
  <td class="tg-6k2t"><a href="http://nlp.stanford.edu/projects/glove/">glove</a> <a href="https://github.com/GradySimon/tensorflow-glove">glove(tensorflow)</a> <a href="https://github.com/hans/glove.py">glove(python)</a></td>
 </tr>
 <tr>
  <td class="tg-031e">02</td>
  <td class="tg-031e"></td>
  <td class="tg-031e"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean</td>
  <td class="tg-yw4l"><a href="https://arxiv.org/pdf/1301.3781.pdf">Efficient Estimation of Word Representations in Vector Space</a></td>
  <td class="tg-yw4l">ICLR</td>
  <td class="tg-yw4l">2013</td>
  <td class="tg-yw4l"><a href="https://code.google.com/archive/p/word2vec/">word2vec</a></td>
 </tr>
 <tr>
  <td class="tg-6k2t">03</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">Fei Sun, Jiafeng Guo, Yanyan Lan, Jun Xu, and Xueqi Cheng</td>
  <td class="tg-6k2t">Inside Out: Two Jointly Predictive Models for Word Representations and Phrase Representations</td>
  <td class="tg-6k2t">AAAI</td>
  <td class="tg-6k2t">2016</td>
  <td class="tg-6k2t"><a href="http://ofey.me/projects/InsideOut/">SEING/BEING</a></td>
 </tr>
 <tr>
  <td class="tg-yw4l">04</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">Minh-Thang Luong, Richard Socher, and Christopher D. Manning</td>
  <td class="tg-yw4l">Better Word Representations with Recursive Neural Networks for Morphology</td>
  <td class="tg-yw4l">CoNLL</td>
  <td class="tg-yw4l">2013</td>
  <td class="tg-yw4l"><a href="http://stanford.edu/~lmthang/morphoNLM/">cwCsmRNN/hsmnCsmRNN</a></td>
 </tr>
 <tr>
  <td class="tg-6k2t">05</td>
  <td class="tg-6k2t">o</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">Ignacio Iacobacci, Mohammad Taher Pilehvar, and Roberto Navigli</td>
  <td class="tg-6k2t">SensEmbed: Learning Sense Embeddings for Word and Relational Similarity</td>
  <td class="tg-6k2t">ACL-IJCNLP</td>
  <td class="tg-6k2t">2015</td>
  <td class="tg-6k2t"><a href="http://lcl.uniroma1.it/sensembed/">SensEmbed</a> <a href="http://lcl.uniroma1.it/babelfied-wikipedia/">BabelNet synsets</a></td>
 </tr>
 <tr>
  <td class="tg-yw4l">06</td>
  <td class="tg-yw4l">o</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">Ignacio Iacobacci, Mohammad Taher Pilehvar, and Roberto Navigli</td>
  <td class="tg-yw4l">Embeddings for word sense disambiguation: An evaluation study</td>
  <td class="tg-yw4l">ACL</td>
  <td class="tg-yw4l">2016</td>
  <td class="tg-yw4l"><a href="https://github.com/iiacobac/ims_wsd_emb">ims_wsd_emb</a></td>
 </tr>
 <tr>
  <td class="tg-6k2t">07</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">Rémi Lebret and Ronan Collobert</td>
  <td class="tg-6k2t">Word Embeddings through Hellinger PCA</td>
  <td class="tg-6k2t">EACL</td>
  <td class="tg-6k2t">2014</td>
  <td class="tg-6k2t"><a href="http://lebret.ch/words/">Hellinger PCA</a></td>
 </tr>
 <tr>
  <td class="tg-yw4l">08</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">Luisa Bentivogli, Pamela Forner, Bernardo Magnini, and Emanuele Pianta </td>
  <td class="tg-yw4l">Revising the wordnet domains hierarchy: semantics, coverage and balancing</td>
  <td class="tg-yw4l">ACL workshop</td>
  <td class="tg-yw4l">2004</td>
  <td class="tg-yw4l"><a href="http://wndomains.fbk.eu/publications.html">WordNet Domains</a></td>
 </tr>
 <tr>
  <td class="tg-6k2t">09</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">John Wieting, Mohit Bansal, Kevin Gimpel, Karen Livescu, and Dan Roth</td>
  <td class="tg-6k2t">From Paraphrase Database to Compositional Model and Back</td>
  <td class="tg-6k2t">TACL</td>
  <td class="tg-6k2t">2015</td>
  <td class="tg-6k2t"><a href="http://ttic.uchicago.edu/~wieting/">Paragram Embeddings</a></td>
 </tr>
 <tr>
  <td class="tg-yw4l">10</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">Jun Suzuki and Masaaki Nagata</td>
  <td class="tg-yw4l">Right-truncatable Neural Word Embeddings</td>
  <td class="tg-yw4l">NAACL</td>
  <td class="tg-yw4l">2016</td>
  <td class="tg-yw4l"><a href="http://www.kecl.ntt.co.jp/icl/lirg/members/jun/agreement.html">Right-truncatable</a></td>
 </tr>
 <tr>
  <td class="tg-6k2t">11</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">o</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">John Wieting, Mohit Bansal, Kevin Gimpel, and Karen Livescu</td>
  <td class="tg-6k2t">Charagram: Embedding words and sentences via character n-grams</td>
  <td class="tg-6k2t">EMNLP</td>
  <td class="tg-6k2t">2016</td>
  <td class="tg-6k2t"><a href="http://ttic.uchicago.edu/~wieting/">CHARAGRAM</a></td>
 </tr>
 <tr>
  <td class="tg-yw4l">12</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">o</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">Hua He, Kevin Gimpel, and Jimmy Lin</td>
  <td class="tg-yw4l">Multi-perspective sentence similarity modeling with convolutional neural networks</td>
  <td class="tg-yw4l">EMNLP</td>
  <td class="tg-yw4l">2015</td>
  <td class="tg-yw4l"><a href="http://hohocode.github.io/textSimilarityConvNet/">MP-CNN-Torch</a></td>
 </tr>
 <tr>
  <td class="tg-6k2t">13</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">o</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">Guang-He Lee, and Yun-Nung Chen</td>
  <td class="tg-6k2t">MUSE: Modularizing Unsupervised Sense Embeddings</td>
  <td class="tg-6k2t">EMNLP</td>
  <td class="tg-6k2t">2017</td>
  <td class="tg-6k2t"><a href="https://github.com/MiuLab/MUSE">MUSE</a></td>
 </tr>
 <tr>
  <td class="tg-yw4l">14</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">Eric H. Huang, Richard Socher, Christopher D. Manning, and Andrew Y. Ng</td>
  <td class="tg-yw4l">Improving word representations via global context and multiple word prototypes</td>
  <td class="tg-yw4l">ACL</td>
  <td class="tg-yw4l">2012</td>
  <td class="tg-yw4l"><a href="http://ai.stanford.edu/~ehhuang/">GC</a> <a href="http://www.socher.org/index.php/Main/ImprovingWordRepresentationsViaGlobalContextAndMultipleWordPrototypes">GC(new)</a></td>
 </tr>
 <tr>
  <td class="tg-6k2t">15</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">Massimiliano Mancini, Jose Camacho-Collados, Ignacio Iacobacci, and Roberto Navigli</td>
  <td class="tg-6k2t">Embedding Words and Senses Together via Joint Knowledge-Enhanced Training</td>
  <td class="tg-6k2t">CoNLL</td>
  <td class="tg-6k2t">2017</td>
  <td class="tg-6k2t"><a href="http://lcl.uniroma1.it/sw2v">SW2V</a></td>
 </tr>
 <tr>
  <td class="tg-yw4l">16</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">o</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">Manaal Faruqui, Jesse Dodge, Sujay Jauhar, Chris Dyer, Eduard Hovy, and Noah Smith</td>
  <td class="tg-yw4l"><a href="https://www.cs.cmu.edu/~hovy/papers/15HLT-retrofitting-word-vectors.pdf">Retrofitting word vectors to semantic lexicons</a></td>
  <td class="tg-yw4l">NAACL</td>
  <td class="tg-yw4l">2015</td>
  <td class="tg-yw4l"><a href="https://github.com/mfaruqui/retrofitting">retrofitting</a></td>
 </tr>
 <tr>
  <td class="tg-6k2t">17</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">o</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">Nikola Mrkšić, Diarmuid Ó Séaghdha, Blaise Thomson, Milica Gašić, Lina Rojas-Barahona, Pei-Hao Su , David Vandyke, Tsung-Hsien Wen, and Steve Young</td>
  <td class="tg-6k2t"><a href="http://www.aclweb.org/anthology/N16-1018">Counter-fitting word vectors to linguistic constraints</a></td>
  <td class="tg-6k2t">HLT-NAACL</td>
  <td class="tg-6k2t">2016</td>
  <td class="tg-6k2t"><a href="https://github.com/nmrksic/counter-fitting">counter-fitting</a></td>
 </tr>
 <tr>
  <td class="tg-yw4l">18</td>
  <td class="tg-yw4l">o</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">o</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">Sujay Kumar Jauhar, Chris Dyer, and Eduard Hovy</td>
  <td class="tg-yw4l"><a href="https://pdfs.semanticscholar.org/8b96/8bfa6a9d3e3713c9c9ff2971e333efe1343b.pdf">Ontologically Grounded Multi-sense Representation Learning for Semantic Vector Space Models</a></td>
  <td class="tg-yw4l">HLT-NAACL</td>
  <td class="tg-yw4l">2015</td>
  <td class="tg-yw4l"><a href="https://github.com/sjauhar/SenseRetrofit">SenseRetrofit</a></td>
 </tr>
 <tr>
  <td class="tg-6k2t">19</td>
  <td class="tg-6k2t">o</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">o</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">Ettinger, Allyson, Philip Resnik, and Marine Carpuat</td>
  <td class="tg-6k2t">Retrofitting Sense-Specific Word Vectors Using Parallel Text</td>
  <td class="tg-6k2t">HLT-NAACL</td>
  <td class="tg-6k2t">2016</td>
  <td class="tg-6k2t"><a href="http://ling.umd.edu/~aetting/retropd.html">sense-specific parallel text</a></td>
 </tr>
 <tr>
  <td class="tg-yw4l">20</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">o</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">Jiahuan Pei, Cong Zhang, Degen Huang, and Jianjun Ma</td>
  <td class="tg-yw4l">Combining word embedding and semantic lexicon for Chinese word similarity computation</td>
  <td class="tg-yw4l">ICCPOL</td>
  <td class="tg-yw4l">2016</td>
  <td class="tg-yw4l"><a href="https://github.com/JiahuanPei/NLPCC-2016-CLSC">NLPCC-2016-CLSC</a> <a href="http://tcci.ccf.org.cn/conference/2016/pages/page05_evadata.html">NLPCC 2016 Shared Task Sample Data</a></td>
 </tr>
 <tr>
  <td class="tg-6k2t">22</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">o</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">Yunfang Wu, and Wei Li</td>
  <td class="tg-6k2t">Overview of the NLPCC-ICCPOL 2016 Shared Task: Chinese Word Similarity Measurement</td>
  <td class="tg-6k2t">ICCPOL</td>
  <td class="tg-6k2t">2016</td>
  <td class="tg-6k2t"></td>
 </tr>
 <tr>
  <td class="tg-yw4l">24</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">o</td>
  <td class="tg-yw4l">Stanisław Jastrzebski, Damian Leśniak, and Wojciech Marian Czarnecki</td>
  <td class="tg-yw4l">How to evaluate word embeddings? On importance of data efficiency and simple supervised tasks</td>
  <td class="tg-yw4l">arxiv</td>
  <td class="tg-yw4l">2017</td>
  <td class="tg-yw4l"><a href="https://github.com/kudkudak/word-embeddings-benchmarks">word-embeddings-benchmarks</a></td>
 </tr>
 <tr>
  <td class="tg-6k2t">25</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">o</td>
  <td class="tg-6k2t">Yulia Tsvetkov, Manaal Faruqui, Wang Ling, Guillaume Lample, and Chris Dyer</td>
  <td class="tg-6k2t">Evaluation of word vector representations by subspace alignment</td>
  <td class="tg-6k2t">EMNLP</td>
  <td class="tg-6k2t">2015</td>
  <td class="tg-6k2t"><a href="https://github.com/ytsvetko/qvec">qvec</a></td>
 </tr>
 <tr>
  <td class="tg-yw4l">26</td>
  <td class="tg-yw4l">o</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">Ben Athiwaratkun and Andrew Gordon Wilson</td>
  <td class="tg-yw4l">Multimodal Word Distributions</td>
  <td class="tg-yw4l">ACL</td>
  <td class="tg-yw4l">2017</td>
  <td class="tg-yw4l"><a href="https://github.com/benathi/word2gm">Word2GM </a></td>
 </tr>
 <tr>
  <td class="tg-6k2t">27</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">Shaohua Li, Jun Zhu and Chunyan Miao</td>
  <td class="tg-6k2t">A Generative Word Embedding Model and its Low Rank Positive Semidefinite Solution</td>
  <td class="tg-6k2t">EMNLP</td>
  <td class="tg-6k2t">2015</td>
  <td class="tg-6k2t"><a href="https://github.com/askerlee/topicvec">TopicVec</a></td>
 </tr>
 <tr>
  <td class="tg-yw4l">28</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">Shaohua Li1, Tat-Seng Chua, Jun Zhu and Chunyan Miao</td>
  <td class="tg-yw4l">Generative Topic Embedding: a Continuous Representation of Documents</td>
  <td class="tg-yw4l">ACL</td>
  <td class="tg-yw4l">2016</td>
  <td class="tg-yw4l"><a href="https://github.com/askerlee/topicvec">TopicVec</a></td>
 </tr>
 <tr>
  <td class="tg-6k2t">29</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">Perozzi, Bryan and Al-Rfou, Rami and Skiena, Steven</td>
  <td class="tg-6k2t"><a href="http://www.perozzi.net/publications/14_kdd_deepwalk.pdf">DeepWalk: Online Learning of Social Representations</a></td>
  <td class="tg-6k2t">KDD</td>
  <td class="tg-6k2t">2014</td>
  <td class="tg-6k2t"><a href="https://github.com/phanein/deepwalk">DeepWalk</a></td>
 </tr>
 <tr>
  <td class="tg-yw4l">30</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">Tang, Jian and Qu, Meng and Wang, Mingzhe and Zhang, Ming and Yan, Jun and Mei, Qiaozhu</td>
  <td class="tg-yw4l"><a href="https://arxiv.org/pdf/1503.03578.pdf">LINE: Large-scale Information Network Embedding</a></td>
  <td class="tg-yw4l">WWW</td>
  <td class="tg-yw4l">2015</td>
  <td class="tg-yw4l"><a href="https://github.com/tangjianpku/LINE">LINE</a></td>
 </tr>
 <tr>
  <td class="tg-6k2t">31</td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t"></td>
  <td class="tg-6k2t">Grover, Aditya and Leskovec, Jure</td>
  <td class="tg-6k2t"><a href="https://arxiv.org/pdf/1607.00653.pdf">node2vec: Scalable Feature Learning for Networks</a></td>
  <td class="tg-6k2t">KDD</td>
  <td class="tg-6k2t">2016</td>
  <td class="tg-6k2t"><a href="https://github.com/aditya-grover/node2vec">node2vec</a></td>
 </tr>
 <tr>
  <td class="tg-yw4l">32</td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l"></td>
  <td class="tg-yw4l">Wang, Daixin and Cui, Peng and Zhu, Wenwu</td>
  <td class="tg-yw4l"><a href="http://www.kdd.org/kdd2016/papers/files/rfp0191-wangAemb.pdf">Structural Deep Network Embedding</a></td>
  <td class="tg-yw4l">KDD</td>
  <td class="tg-yw4l">2016</td>
  <td class="tg-yw4l"><a href="https://github.com/suanrong/SDNE">SDNE</a></td>
 </tr>
</table>
<script type="text/javascript" charset="utf-8">var TgTableSort=window.TgTableSort||function(n,t){"use strict";function r(n,t){for(var e=[],o=n.childNodes,i=0;i<o.length;++i){var u=o[i];if("."==t.substring(0,1)){var a=t.substring(1);f(u,a)&&e.push(u)}else u.nodeName.toLowerCase()==t&&e.push(u);var c=r(u,t);e=e.concat(c)}return e}function e(n,t){var e=[],o=r(n,"tr");return o.forEach(function(n){var o=r(n,"td");t>=0&&t<o.length&&e.push(o[t])}),e}function o(n){return n.textContent||n.innerText||""}function i(n){return n.innerHTML||""}function u(n,t){var r=e(n,t);return r.map(o)}function a(n,t){var r=e(n,t);return r.map(i)}function c(n){var t=n.className||"";return t.match(/\S+/g)||[]}function f(n,t){return-1!=c(n).indexOf(t)}function s(n,t){f(n,t)||(n.className+=" "+t)}function d(n,t){if(f(n,t)){var r=c(n),e=r.indexOf(t);r.splice(e,1),n.className=r.join(" ")}}function v(n){d(n,L),d(n,E)}function l(n,t,e){r(n,"."+E).map(v),r(n,"."+L).map(v),e==T?s(t,E):s(t,L)}function g(n){return function(t,r){var e=n*t.str.localeCompare(r.str);return 0==e&&(e=t.index-r.index),e}}function h(n){return function(t,r){var e=+t.str,o=+r.str;return e==o?t.index-r.index:n*(e-o)}}function m(n,t,r){var e=u(n,t),o=e.map(function(n,t){return{str:n,index:t}}),i=e&&-1==e.map(isNaN).indexOf(!0),a=i?h(r):g(r);return o.sort(a),o.map(function(n){return n.index})}function p(n,t,r,o){for(var i=f(o,E)?N:T,u=m(n,r,i),c=0;t>c;++c){var s=e(n,c),d=a(n,c);s.forEach(function(n,t){n.innerHTML=d[u[t]]})}l(n,o,i)}function x(n,t){var r=t.length;t.forEach(function(t,e){t.addEventListener("click",function(){p(n,r,e,t)}),s(t,"tg-sort-header")})}var T=1,N=-1,E="tg-sort-asc",L="tg-sort-desc";return function(t){var e=n.getElementById(t),o=r(e,"tr"),i=o.length>0?r(o[0],"td"):[];0==i.length&&(i=r(o[0],"th"));for(var u=1;u<o.length;++u){var a=r(o[u],"td");if(a.length!=i.length)return}x(e,i)}}(document);document.addEventListener("DOMContentLoaded",function(n){TgTableSort("tg-Jb0Jr")});</script>

<a href="https://github.com/Hironsan/awesome-embedding-models">awesome-embedding-models</a>
<br>
<a href="https://github.com/keon/awesome-nlp">awesome-nlp</a>
<br>
<a href="https://github.com/thunlp/NRLpapers">Must-read papers on network representation learning network embedding</a>
<br>
<a href="https://github.com/MaxwellRebo/awesome-2vec">awesome-2vec</a>
<br>

</table></div></div>

</body></html>